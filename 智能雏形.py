"""
AIå­¦ç”Ÿï¼šå•ä¸€æ™ºèƒ½ä½“çš„4380æ¬¡å±•å¼€
æ ¸å¿ƒç†è§£ï¼šä¸æ˜¯4380ä¸ªå¹¶è¡Œå¯¹è±¡ï¼Œè€Œæ˜¯åŒä¸€ä¸ªæ™ºèƒ½ä½“åœ¨æ—¶é—´ç»´åº¦ä¸Šçš„4380æ¬¡çŠ¶æ€æ¼”åŒ–
ä¿®å¤ç‰ˆæœ¬ï¼šè§£å†³KeyErroré—®é¢˜
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
from dataclasses import dataclass
import random
from collections import deque, defaultdict
# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ ä»¥ä¸‹ä»£ç 
import matplotlib
import matplotlib.pyplot as plt

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']  # è®¾ç½®å­—ä½“
plt.rcParams['axes.unicode_minus'] = False  # æ­£å¸¸æ˜¾ç¤ºè´Ÿå·


# ======================
# æ ¸å¿ƒï¼šå•ä¸€æ™ºèƒ½ä½“å®šä¹‰
# ======================

class SingleAIStudent:
    """å•ä¸€AIå­¦ç”Ÿæ™ºèƒ½ä½“ - å°†åœ¨4380å¤©å†…æŒç»­æ¼”åŒ–"""

    def __init__(self, name="AIå­¦ç”Ÿ", initial_age=6):
        self.name = name
        self.age_days = initial_age * 365  # åˆå§‹å¤©æ•°

        # ğŸ”¥ æ ¸å¿ƒï¼šåªæœ‰ä¸€ä¸ªæ™ºèƒ½ä½“ï¼Œä½†éšæ—¶é—´æ¼”åŒ–
        self.cognitive_state = self._initialize_state()
        self.knowledge_base = {}
        self.learning_history = []  # æ‰€æœ‰å†å²è®°å½•

        # è¿‡ç¨‹å¼•æ“ï¼ˆåœ¨æ—¶é—´ä¸­å±•å¼€çš„æ ¸å¿ƒï¼‰
        self.process_engine = CognitiveProcessEngine()

        # ä¸–ç•Œæ¨¡å‹ï¼ˆéšæ—¶é—´å­¦ä¹ ï¼‰
        self.world_model = StudentWorldModel()

        # å½“å‰ç›®æ ‡ï¼ˆéšæ—¶é—´å˜åŒ–ï¼‰
        self.current_goals = self._get_age_based_goals()

        print(f"ğŸ“ åˆ›å»ºå•ä¸€AIå­¦ç”Ÿ: {name}")
        print(f"   å°†ä»è¿™ä¸ªçŠ¶æ€å¼€å§‹ï¼Œåœ¨4380å¤©å†…æŒç»­æ¼”åŒ–")
        print(f"   åˆå§‹è®¤çŸ¥çŠ¶æ€: {self._summarize_state()}")

    def _initialize_state(self):
        """åˆå§‹åŒ–è®¤çŸ¥çŠ¶æ€"""
        return {
            # è®¤çŸ¥èƒ½åŠ›ç»´åº¦ï¼ˆéšæ—¶é—´å‘å±•ï¼‰
            "working_memory": 0.3,
            "processing_speed": 0.4,
            "logical_reasoning": 0.3,
            "abstract_thinking": 0.2,
            "creativity": 0.4,
            "focus": 0.5,

            # æƒ…æ„Ÿä¸åŠ¨æœºç»´åº¦ï¼ˆæ¯å¤©æ³¢åŠ¨ï¼‰
            "motivation": 0.7,
            "curiosity": 0.8,
            "confidence": 0.6,
            "frustration": 0.2,

            # å…ƒè®¤çŸ¥ç»´åº¦ï¼ˆéšæ—¶é—´å­¦ä¹ ï¼‰
            "self_awareness": 0.4,
            "strategy_knowledge": 0.3,
            "error_monitoring": 0.3,

            # ç”Ÿç†çŠ¶æ€ï¼ˆæ¯å¤©å˜åŒ–ï¼‰
            "energy": 0.8,
            "stress": 0.2
        }

    def _get_age_based_goals(self):
        """æ ¹æ®å¹´é¾„è·å–ç›®æ ‡"""
        age_years = self.age_days // 365

        if age_years < 9:
            return ["åŸºç¡€æŠ€èƒ½", "å¥½å¥‡æ¢ç´¢", "ç¤¾äº¤å­¦ä¹ "]
        elif age_years < 13:
            return ["ç³»ç»ŸçŸ¥è¯†", "é€»è¾‘æ€ç»´", "å…´è¶£å‘å±•"]
        elif age_years < 16:
            return ["æŠ½è±¡æ€ç»´", "å­¦ç§‘æ·±åŒ–", "è‡ªæˆ‘è®¤çŸ¥"]
        else:
            return ["ä¸“ä¸šæ–¹å‘", "æ‰¹åˆ¤æ€ç»´", "ç‹¬ç«‹å­¦ä¹ "]

    def _summarize_state(self):
        """ç®€è¦æ€»ç»“çŠ¶æ€"""
        return {
            "knowledge_domains": len(self.knowledge_base),
            "avg_knowledge": np.mean(list(self.knowledge_base.values())) if self.knowledge_base else 0,
            "cognitive_ability": np.mean(
                [self.cognitive_state[k] for k in ["logical_reasoning", "abstract_thinking", "creativity"]]),
            "motivational_state": self.cognitive_state["motivation"]
        }


# ======================
# è¿‡ç¨‹å¼•æ“ï¼šåœ¨æ—¶é—´ä¸­å±•å¼€æ€è€ƒ
# ======================

class CognitiveProcessEngine:
    """è®¤çŸ¥è¿‡ç¨‹å¼•æ“ - æ™ºèƒ½åœ¨æ—¶é—´ä¸­å±•å¼€"""

    def execute(self, start_state, material, world_model):
        """æ‰§è¡Œè®¤çŸ¥è¿‡ç¨‹"""

        # ğŸ”¥ æ ¸å¿ƒï¼šæ€è€ƒè¿‡ç¨‹åœ¨å†…éƒ¨æ—¶é—´ä¸­å±•å¼€
        thought_steps = []
        current_state = start_state.copy()

        # æ­¥éª¤1ï¼šæ„ŸçŸ¥ä¸ç¼–ç 
        encoded = self._encode_material(current_state, material)
        # åªæ›´æ–°æˆ–æ·»åŠ æ–°é”®åˆ°å½“å‰çŠ¶æ€
        current_state.update(encoded)
        thought_steps.append({"step": "encode", "state": current_state.copy()})

        # æ­¥éª¤2ï¼šä¸å·²æœ‰çŸ¥è¯†æ•´åˆ
        if "prior_knowledge" in material and material["prior_knowledge"] > 0.3:
            integrated = self._integrate_with_prior(current_state, encoded, material)
            current_state.update(integrated)
            thought_steps.append({"step": "integrate", "state": current_state.copy()})

        # æ­¥éª¤3ï¼šç†è§£ä¸æ¨ç†
        understood = self._comprehend(current_state, material)
        current_state.update(understood)
        thought_steps.append({"step": "comprehend", "state": current_state.copy()})

        # æ­¥éª¤4ï¼šåº”ç”¨ä¸è¿ç§»
        if random.random() > 0.3:  # 70%æ¦‚ç‡å°è¯•è¿ç§»
            transferred = self._transfer_learning(current_state, material)
            current_state.update(transferred)
            thought_steps.append({"step": "transfer", "state": current_state.copy()})

        # æ­¥éª¤5ï¼šåæ€ä¸å·©å›º
        reflected = self._reflect_on_learning(current_state, thought_steps)
        current_state.update(reflected)
        thought_steps.append({"step": "reflect", "state": current_state.copy()})

        # è®¡ç®—å­¦ä¹ æ”¶ç›Š
        learning_gain = self._calculate_learning_gain(start_state, current_state, material)

        # æ£€æŸ¥çªç ´
        breakthrough = learning_gain > 0.15 and len(thought_steps) > 3

        # æŒ£æ‰ç¨‹åº¦
        struggle = 1.0 - (len([s for s in thought_steps if "state" in s]) / 5.0)

        return current_state, {
            "thought_steps": thought_steps,
            "learning_gain": learning_gain,
            "process_length": len(thought_steps),
            "breakthrough": breakthrough,
            "struggle": struggle,
            "material_difficulty": material.get("difficulty", 0.5)
        }

    def _encode_material(self, state, material):
        """ç¼–ç å­¦ä¹ ææ–™"""
        # ç¼–ç æ•ˆç‡å—å·¥ä½œè®°å¿†å’Œä¸“æ³¨åŠ›å½±å“
        encoding_efficiency = state["working_memory"] * 0.5 + state["focus"] * 0.5
        return {
            "encoded_strength": encoding_efficiency * material.get("difficulty", 0.5),
            "attention_level": state["focus"]
        }

    def _integrate_with_prior(self, state, encoded, material):
        """ä¸å…ˆå‰çŸ¥è¯†æ•´åˆ"""
        prior_strength = material.get("prior_knowledge", 0)
        integration_quality = state["logical_reasoning"] * 0.3 + prior_strength * 0.7

        return {
            "integration_quality": integration_quality,
            "schema_strength": min(1.0, prior_strength + integration_quality * 0.1)
        }

    def _comprehend(self, state, material):
        """ç†è§£è¿‡ç¨‹"""
        comprehension = state["logical_reasoning"] * 0.4 + state["abstract_thinking"] * 0.3 + state["creativity"] * 0.3
        comprehension *= (1.0 - material.get("difficulty", 0.5) * 0.3)

        return {
            "comprehension_level": comprehension,
            "conceptual_clarity": comprehension * state["focus"]
        }

    def _transfer_learning(self, state, material):
        """è¿ç§»å­¦ä¹ """
        transfer_ability = state["abstract_thinking"] * 0.5 + state["creativity"] * 0.5
        return {
            "transfer_success": random.random() < transfer_ability,
            "analogies_made": 1 if transfer_ability > 0.6 else 0
        }

    def _reflect_on_learning(self, state, thought_steps):
        """åæ€å­¦ä¹ """
        reflection_depth = state["self_awareness"] * 0.7 + state["error_monitoring"] * 0.3
        insights = len(thought_steps) * 0.1 * reflection_depth

        return {
            "insights_gained": insights,
            "metacognitive_awareness": reflection_depth,
            "confidence_change": insights * 0.2
        }

    def _calculate_learning_gain(self, start_state, end_state, material):
        """è®¡ç®—å­¦ä¹ æ”¶ç›Š"""
        # åªè®¡ç®—ä¸¤ä¸ªçŠ¶æ€ä¸­éƒ½å­˜åœ¨çš„é”®
        common_keys = set(start_state.keys()) & set(end_state.keys())
        dimension_improvements = []

        for key in ["logical_reasoning", "abstract_thinking", "creativity", "confidence"]:
            if key in common_keys:
                improvement = end_state[key] - start_state[key]
                dimension_improvements.append(max(0, improvement))

        avg_improvement = np.mean(dimension_improvements) if dimension_improvements else 0

        # ææ–™éš¾åº¦è°ƒæ•´
        difficulty_factor = 1.0 - material.get("difficulty", 0.5) * 0.2

        return avg_improvement * difficulty_factor * 10  # æ”¾å¤§åˆ°åˆç†èŒƒå›´


# ======================
# ä¸–ç•Œæ¨¡å‹ï¼šéšæ—¶é—´å­¦ä¹ è§„å¾‹
# ======================

class StudentWorldModel:
    """å­¦ç”Ÿå¿ƒæ™ºä¸–ç•Œæ¨¡å‹ - éšæ—¶é—´å­¦ä¹ """

    def __init__(self):
        self.observations = []
        self.learned_patterns = {
            "best_learning_time": "morning",  # éšæ—¶é—´è°ƒæ•´
            "optimal_study_duration": 45,  # åˆ†é’Ÿ
            "effective_strategies": [],  # é€æ¸å‘ç°
            "personal_rhythms": {}  # ä¸ªäººå­¦ä¹ èŠ‚å¾‹
        }

    def learn_from_experience(self, experience):
        """ä»ç»éªŒä¸­å­¦ä¹ """
        self.observations.append(experience)

        # å½“æœ‰è¶³å¤Ÿæ•°æ®æ—¶ï¼Œå¼€å§‹å‘ç°æ¨¡å¼
        if len(self.observations) > 100:
            self._discover_patterns()

        # ç®€å•å­¦ä¹ ï¼šè®°å½•ä»€ä¹ˆæƒ…å†µä¸‹å­¦ä¹ æ•ˆæœå¥½
        if experience["gain"] > 0.1:  # å­¦ä¹ æ•ˆæœå¥½
            state_before = experience["state_before"]

            # è®°å½•é«˜åŠ¨æœºæ—¶çš„å­¦ä¹ æ•ˆæœ
            if state_before.get("motivation", 0) > 0.7:
                if "high_motivation_success" not in self.learned_patterns:
                    self.learned_patterns["high_motivation_success"] = []
                self.learned_patterns["high_motivation_success"].append(experience["gain"])

    def _discover_patterns(self):
        """å‘ç°å­¦ä¹ æ¨¡å¼"""
        if len(self.observations) < 50:
            return

        # åˆ†ææœ€ä½³å­¦ä¹ æ—¶é—´
        morning_gains = []
        afternoon_gains = []

        for obs in self.observations[-50:]:
            # ç®€å•æ¨¡æ‹Ÿï¼šæ ¹æ®dayçš„å¥‡å¶æ¨¡æ‹Ÿä¸Šä¸‹åˆ
            if obs["day"] % 2 == 0:
                morning_gains.append(obs["gain"])
            else:
                afternoon_gains.append(obs["gain"])

        if morning_gains and afternoon_gains:
            avg_morning = np.mean(morning_gains)
            avg_afternoon = np.mean(afternoon_gains)

            if avg_morning > avg_afternoon:
                self.learned_patterns["best_learning_time"] = "morning"
            else:
                self.learned_patterns["best_learning_time"] = "afternoon"

        # å‘ç°æœ‰æ•ˆç­–ç•¥
        successful_obs = [obs for obs in self.observations if obs["gain"] > 0.15]
        if successful_obs:
            strategies = [obs["action"].get("strategy", "") for obs in successful_obs]
            strategy_counts = {}
            for s in strategies:
                if s:
                    strategy_counts[s] = strategy_counts.get(s, 0) + 1

            if strategy_counts:
                best_strategy = max(strategy_counts, key=strategy_counts.get)
                if best_strategy not in self.learned_patterns["effective_strategies"]:
                    self.learned_patterns["effective_strategies"].append(best_strategy)

    def predict(self, current_state, planned_action):
        """é¢„æµ‹è¡ŒåŠ¨æ•ˆæœ"""
        # åŸºäºå·²å­¦åˆ°çš„æ¨¡å¼åšç®€å•é¢„æµ‹
        prediction = {
            "expected_gain": 0.08,  # åŸºç¡€é¢„æœŸ
            "confidence": 0.6
        }

        # åº”ç”¨å·²å­¦æ¨¡å¼
        if self.learned_patterns["best_learning_time"] == "morning":
            # å¦‚æœæ˜¯"ä¸Šåˆ"ä¸”çŠ¶æ€å¥½ï¼Œæé«˜é¢„æœŸ
            if current_state.get("energy", 0) > 0.7:
                prediction["expected_gain"] += 0.03

        # åº”ç”¨æœ‰æ•ˆç­–ç•¥çŸ¥è¯†
        action_strategy = planned_action.get("strategy", "")
        if action_strategy in self.learned_patterns["effective_strategies"]:
            prediction["expected_gain"] += 0.04
            prediction["confidence"] += 0.1

        # çŠ¶æ€å½±å“
        if current_state.get("motivation", 0) > 0.7:
            prediction["expected_gain"] += 0.02

        if current_state.get("focus", 0) > 0.7:
            prediction["expected_gain"] += 0.02

        return prediction


# ======================
# è¯¾ç¨‹ç”Ÿæˆå™¨
# ======================

class CurriculumGenerator:
    """éšæ—¶é—´æ¼”åŒ–çš„è¯¾ç¨‹ç”Ÿæˆ"""

    def generate_for_day(self, age_days):
        """ç”ŸæˆæŸä¸€å¤©çš„è¯¾ç¨‹"""
        age_years = age_days // 365

        # åŸºç¡€ä¸»é¢˜
        base_subjects = ["æ•°å­¦", "è¯­æ–‡", "ç§‘å­¦", "å†å²", "è‰ºæœ¯", "ä½“è‚²"]

        # éšç€å¹´é¾„å¢åŠ ä¸»é¢˜å¤æ‚åº¦
        if age_years < 9:
            topics = [f"{subject}_åŸºç¡€" for subject in base_subjects[:4]]
        elif age_years < 13:
            topics = [f"{subject}_è¿›é˜¶" for subject in base_subjects]
        elif age_years < 16:
            topics = [f"{subject}_æ·±å…¥" for subject in base_subjects]
        else:
            topics = [f"{subject}_ä¸“ä¸š" for subject in base_subjects]

        # æ¯æ—¥é€‰æ‹©ä¸€ä¸ªä¸»é¢˜
        selected = random.choice(topics)

        # éš¾åº¦éšå¹´é¾„å¢åŠ 
        base_difficulty = min(0.9, 0.3 + age_years * 0.04)

        return {
            "topics": [selected],
            "difficulty": random.uniform(base_difficulty - 0.1, base_difficulty + 0.1),
            "social": random.choice(["individual", "group"]),
            "duration": random.randint(40, 60)
        }


# ======================
# è¾…åŠ©å‡½æ•°
# ======================

def _perceive_environment(student, curriculum):
    """æ„ŸçŸ¥ç¯å¢ƒ"""
    return {
        "available_topics": curriculum.get("topics", []),
        "difficulty": curriculum.get("difficulty", 0.5),
        "social_context": curriculum.get("social", "individual"),
        "student_mood": student.cognitive_state["motivation"] * 0.7 + student.cognitive_state["curiosity"] * 0.3
    }


def _make_learning_decision(student, perception):
    """åˆ¶å®šå­¦ä¹ å†³ç­–"""
    # åŸºäºç›®æ ‡ã€å…´è¶£ã€çŸ¥è¯†ç¼ºå£å†³ç­–
    topics = perception["available_topics"]

    if not topics:
        return {"selected_topic": "general_learning", "strategy": "self_study"}

    # ç›®æ ‡åŒ¹é…
    for goal in student.current_goals:
        for topic in topics:
            if goal in topic or any(word in topic for word in goal.split("_")):
                return {"selected_topic": topic, "strategy": "goal_driven"}

    # å…´è¶£åŒ¹é…
    topic_interests = {topic: random.uniform(0.3, 0.9) for topic in topics}
    most_interesting = max(topic_interests, key=topic_interests.get)

    # çŸ¥è¯†ç¼ºå£åŒ¹é…
    if student.knowledge_base:
        gaps = {topic: 1.0 - student.knowledge_base.get(topic, 0) for topic in topics}
        biggest_gap = max(gaps, key=gaps.get)

        # æƒè¡¡ï¼šå…´è¶£ vs çŸ¥è¯†ç¼ºå£
        if gaps[biggest_gap] > 0.6:  # ç¼ºå£å¾ˆå¤§
            selected = biggest_gap
        else:
            selected = most_interesting
    else:
        selected = most_interesting

    return {
        "selected_topic": selected,
        "strategy": "interest_based" if selected == most_interesting else "gap_filling",
        "interest_score": topic_interests.get(selected, 0.5),
        "gap_score": 1.0 - student.knowledge_base.get(selected, 0) if student.knowledge_base else 0.5
    }


def _apply_daily_adjustments(student):
    """åº”ç”¨æ¯æ—¥è°ƒæ•´"""
    # é—å¿˜æ›²çº¿
    for topic in list(student.knowledge_base.keys()):
        # ç®€å•é—å¿˜æ¨¡å‹
        forgetting_rate = 0.01  # æ¯å¤©é—å¿˜1%
        student.knowledge_base[topic] *= (1 - forgetting_rate)

    # ç–²åŠ³æ¢å¤
    student.cognitive_state["energy"] = min(1.0, student.cognitive_state["energy"] + 0.3)

    # åŠ¨æœºæ³¢åŠ¨
    motivation_change = random.uniform(-0.05, 0.05)
    student.cognitive_state["motivation"] = max(0.1, min(1.0,
                                                         student.cognitive_state["motivation"] + motivation_change))


# ======================
# æ™ºèƒ½ä½“çš„å•æ—¥å±•å¼€ï¼ˆå…³é”®å‡½æ•°ï¼‰
# ======================

def single_day_unfolding(student, day_curriculum):
    """
    å•ä¸€æ™ºèƒ½ä½“çš„ä¸€æ—¥å±•å¼€
    è¿”å›ï¼šè¿™ä¸€å¤©çš„å­¦ä¹ å¿«ç…§ï¼ˆç¬¬Nä¸ªagentï¼‰
    """

    # 1. è·å–å½“å‰çŠ¶æ€ï¼ˆè¿™ä¸€å¤©å¼€å§‹æ—¶çš„çŠ¶æ€ï¼‰
    start_state = student.cognitive_state.copy()
    start_knowledge = student.knowledge_base.copy()

    # 2. å½“æ—¥ç›®æ ‡æ›´æ–°
    student.current_goals = student._get_age_based_goals()

    # 3. æ„ŸçŸ¥ä¸å†³ç­–
    perception = _perceive_environment(student, day_curriculum)
    decision = _make_learning_decision(student, perception)

    # 4. å­¦ä¹ è¿‡ç¨‹æ‰§è¡Œ
    learning_material = {
        "topic": decision["selected_topic"],
        "difficulty": perception["difficulty"],
        "prior_knowledge": student.knowledge_base.get(decision["selected_topic"], 0.2)
    }

    # æ ¸å¿ƒï¼šæ‰§è¡Œè®¤çŸ¥è¿‡ç¨‹
    final_state, process_trace = student.process_engine.execute(
        start_state, learning_material, student.world_model
    )

    # 5. æ›´æ–°æ™ºèƒ½ä½“çŠ¶æ€ï¼ˆæ™ºèƒ½ä½“æ¼”åŒ–ï¼ï¼‰
    # å®‰å…¨æ›´æ–°ï¼šåˆå¹¶æœ€ç»ˆçŠ¶æ€åˆ°è®¤çŸ¥çŠ¶æ€
    for key, value in final_state.items():
        student.cognitive_state[key] = value

    # 6. çŸ¥è¯†æ›´æ–°
    knowledge_gain = process_trace["learning_gain"]
    topic = decision["selected_topic"]
    student.knowledge_base[topic] = student.knowledge_base.get(topic, 0) + knowledge_gain

    # 7. ä¸–ç•Œæ¨¡å‹å­¦ä¹ 
    student.world_model.learn_from_experience({
        "day": student.age_days,
        "state_before": start_state,
        "action": decision,
        "state_after": final_state,
        "gain": knowledge_gain
    })

    # 8. æ¯æ—¥çŠ¶æ€è°ƒæ•´ï¼ˆé—å¿˜ã€ç–²åŠ³ç­‰ï¼‰
    _apply_daily_adjustments(student)

    # 9. å¹´é¾„å¢é•¿
    student.age_days += 1

    # 10. è®°å½•å†å²
    # ä¿®å¤KeyErrorï¼šåªè®¡ç®—ä¸¤ä¸ªçŠ¶æ€ä¸­éƒ½å­˜åœ¨çš„é”®çš„å·®å€¼
    common_keys = set(start_state.keys()) & set(final_state.keys())
    state_delta = {k: final_state[k] - start_state.get(k, 0) for k in common_keys}

    daily_snapshot = {
        "day": student.age_days - 1,  # è¿™ä¸€å¤©ç»“æŸæ—¶çš„å¤©æ•°
        "age_years": (student.age_days - 1) // 365,

        # çŠ¶æ€å¿«ç…§ï¼ˆè¿™å°±æ˜¯ç¬¬Nä¸ª"agent"ï¼‰
        "state_snapshot": {
            "cognitive": student.cognitive_state.copy(),
            "knowledge": student.knowledge_base.copy(),
            "goals": student.current_goals.copy()
        },

        # è¿‡ç¨‹è®°å½•
        "process": process_trace,
        "decision": decision,
        "perception": perception,

        # å˜åŒ–é‡ï¼ˆä¿®å¤åçš„ï¼‰
        "state_delta": state_delta,
        "knowledge_gain": knowledge_gain,

        # å…ƒä¿¡æ¯
        "is_breakthrough": process_trace.get("breakthrough", False),
        "struggle_level": process_trace.get("struggle", 0)
    }

    student.learning_history.append(daily_snapshot)

    return daily_snapshot


# ======================
# ä¸»ç³»ç»Ÿï¼š4380æ¬¡å±•å¼€
# ======================

class AIStudentSystem:
    """AIå­¦ç”Ÿç³»ç»Ÿï¼šå•ä¸€æ™ºèƒ½ä½“çš„4380æ¬¡å±•å¼€"""

    def __init__(self, name="AIå­¦ç”Ÿ", start_age=6, total_years=12):
        self.name = name
        self.start_age = start_age
        self.total_years = total_years
        self.total_days = total_years * 365

        # ğŸ”¥ æ ¸å¿ƒï¼šåªæœ‰ä¸€ä¸ªæ™ºèƒ½ä½“
        print("=" * 60)
        print(f"ğŸ“ åˆ›å»ºAIå­¦ç”Ÿç³»ç»Ÿ")
        print(f"   å­¦ç”Ÿå§“å: {name}")
        print(f"   èµ·å§‹å¹´é¾„: {start_age}å²")
        print(f"   æ€»å¹´é™: {total_years}å¹´ ({self.total_days}å¤©)")
        print(f"   ğŸ”¥ æ ¸å¿ƒå“²å­¦: 1ä¸ªæ™ºèƒ½ä½“ Ã— {self.total_days}æ¬¡å±•å¼€")
        print("=" * 60)

        self.student = SingleAIStudent(name, start_age)
        self.curriculum_gen = CurriculumGenerator()

        # è®°å½•æ‰€æœ‰å±•å¼€çš„å¿«ç…§
        self.all_snapshots = []  # è¿™å°±æ˜¯4380ä¸ª"agent"çš„å¿«ç…§

    def simulate_full_development(self):
        """æ¨¡æ‹Ÿå®Œæ•´å‘å±•è¿‡ç¨‹"""
        print(f"\nğŸš€ å¼€å§‹æ¨¡æ‹Ÿ {self.total_years} å¹´å‘å±•...")
        print(f"   æ¯å¤©æ‰§è¡Œä¸€æ¬¡æ™ºèƒ½ä½“å±•å¼€")
        print(f"   å°†ç”Ÿæˆ {self.total_days} ä¸ªçŠ¶æ€å¿«ç…§")
        print("-" * 60)

        for day in range(self.total_days):
            # ç”Ÿæˆå½“æ—¥è¯¾ç¨‹
            curriculum = self.curriculum_gen.generate_for_day(self.student.age_days)

            # ğŸ”¥ æ ¸å¿ƒï¼šæ™ºèƒ½ä½“å•æ—¥å±•å¼€
            snapshot = single_day_unfolding(self.student, curriculum)

            self.all_snapshots.append(snapshot)

            # è¿›åº¦æŠ¥å‘Š
            if day % 365 == 0 and day > 0:
                self._annual_report(day)

            if day % 100 == 0:
                self._progress_update(day)

        print("=" * 60)
        print(f"âœ… æ¨¡æ‹Ÿå®Œæˆ!")
        print(f"   æ€»å±•å¼€æ¬¡æ•°: {len(self.all_snapshots)}")
        print(f"   æœ€ç»ˆå¹´é¾„: {self.student.age_days // 365}å²")
        print(f"   çŸ¥è¯†é¢†åŸŸæ•°: {len(self.student.knowledge_base)}")
        print("=" * 60)

        return self.all_snapshots

    def _annual_report(self, day):
        """å¹´åº¦æŠ¥å‘Š"""
        year = day // 365 + self.start_age
        snapshot = self.all_snapshots[-1]

        print(f"\nğŸ“… ç¬¬{year}å¹´æŠ¥å‘Š:")
        print(f"   è®¤çŸ¥èƒ½åŠ›: {snapshot['state_snapshot']['cognitive']['logical_reasoning']:.2f}")
        print(f"   åŠ¨æœºæ°´å¹³: {snapshot['state_snapshot']['cognitive']['motivation']:.2f}")
        print(f"   çŸ¥è¯†é¢†åŸŸ: {len(snapshot['state_snapshot']['knowledge'])}ä¸ª")

        # å¹´åº¦å­¦ä¹ ç»Ÿè®¡
        year_snapshots = self.all_snapshots[-365:]
        breakthroughs = sum(1 for s in year_snapshots if s.get('is_breakthrough', False))
        avg_gain = np.mean([s.get('knowledge_gain', 0) for s in year_snapshots])

        print(f"   çªç ´æ¬¡æ•°: {breakthroughs}")
        print(f"   å¹³å‡æ—¥æ”¶ç›Š: {avg_gain:.3f}")

    def _progress_update(self, day):
        """è¿›åº¦æ›´æ–°"""
        if day > 0 and day % 100 == 0:
            snapshot = self.all_snapshots[-1]
            print(f"   Day {day}: çŸ¥è¯†={len(snapshot['state_snapshot']['knowledge'])}é¢†åŸŸ, "
                  f"åŠ¨æœº={snapshot['state_snapshot']['cognitive']['motivation']:.2f}")

    def get_agent_at_day(self, day):
        """è·å–ç¬¬Nå¤©çš„"agent"ï¼ˆçŠ¶æ€å¿«ç…§ï¼‰"""
        if 0 <= day < len(self.all_snapshots):
            return self.all_snapshots[day]
        return None

    def visualize_development(self):
        """å¯è§†åŒ–å‘å±•è¿‡ç¨‹"""
        if not self.all_snapshots:
            print("âŒ æ²¡æœ‰æ¨¡æ‹Ÿæ•°æ®")
            return

        # æå–æ•°æ®
        days = list(range(len(self.all_snapshots)))
        ages = [s['age_years'] for s in self.all_snapshots]

        # è®¤çŸ¥èƒ½åŠ›
        reasoning = [s['state_snapshot']['cognitive']['logical_reasoning'] for s in self.all_snapshots]
        abstract = [s['state_snapshot']['cognitive']['abstract_thinking'] for s in self.all_snapshots]

        # åŠ¨æœºä¸çŸ¥è¯†
        motivation = [s['state_snapshot']['cognitive']['motivation'] for s in self.all_snapshots]
        knowledge_domains = [len(s['state_snapshot']['knowledge']) for s in self.all_snapshots]

        # å­¦ä¹ æ”¶ç›Š
        gains = [s.get('knowledge_gain', 0) for s in self.all_snapshots]

        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))

        # 1. è®¤çŸ¥èƒ½åŠ›å‘å±•
        axes[0, 0].plot(days, reasoning, 'b-', label='é€»è¾‘æ¨ç†', alpha=0.7)
        axes[0, 0].plot(days, abstract, 'r-', label='æŠ½è±¡æ€ç»´', alpha=0.7)
        axes[0, 0].set_title('è®¤çŸ¥èƒ½åŠ›å‘å±•')
        axes[0, 0].set_xlabel('å¤©æ•°')
        axes[0, 0].set_ylabel('èƒ½åŠ›å€¼')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        # 2. åŠ¨æœºå˜åŒ–
        axes[0, 1].plot(days, motivation, 'g-', alpha=0.7)
        axes[0, 1].set_title('åŠ¨æœºæ°´å¹³å˜åŒ–')
        axes[0, 1].set_xlabel('å¤©æ•°')
        axes[0, 1].set_ylabel('åŠ¨æœº')
        axes[0, 1].grid(True, alpha=0.3)

        # 3. çŸ¥è¯†é¢†åŸŸå¢é•¿
        axes[1, 0].plot(days, knowledge_domains, 'purple', alpha=0.7)
        axes[1, 0].set_title('çŸ¥è¯†é¢†åŸŸæ‰©å±•')
        axes[1, 0].set_xlabel('å¤©æ•°')
        axes[1, 0].set_ylabel('é¢†åŸŸæ•°é‡')
        axes[1, 0].grid(True, alpha=0.3)

        # 4. æ—¥å­¦ä¹ æ”¶ç›Šï¼ˆå¹³æ»‘ï¼‰
        if len(gains) > 30:
            window = 30
            gains_smooth = np.convolve(gains, np.ones(window) / window, mode='valid')
            days_smooth = days[window - 1:]
            axes[1, 1].plot(days_smooth, gains_smooth, 'orange', alpha=0.7)
            axes[1, 1].set_title(f'å­¦ä¹ æ”¶ç›Šï¼ˆ{window}å¤©å¹³æ»‘ï¼‰')
            axes[1, 1].set_xlabel('å¤©æ•°')
            axes[1, 1].set_ylabel('æ—¥æ”¶ç›Š')
            axes[1, 1].grid(True, alpha=0.3)

        plt.suptitle(f'{self.name}çš„å‘å±•è½¨è¿¹ï¼ˆ{self.total_years}å¹´ï¼‰', fontsize=14, y=1.02)
        plt.tight_layout()
        plt.show()

        # æ‰“å°ä¸–ç•Œæ¨¡å‹å­¦åˆ°çš„çŸ¥è¯†
        print("\nğŸ§  ä¸–ç•Œæ¨¡å‹å­¦åˆ°çš„è§„å¾‹:")
        for key, value in self.student.world_model.learned_patterns.items():
            if isinstance(value, list) and len(value) > 0:
                if len(value) > 3:
                    print(f"   {key}: {value[:3]}... (å…±{len(value)}æ¡)")
                else:
                    print(f"   {key}: {value}")
            else:
                print(f"   {key}: {value}")


# ======================
# æ¼”ç¤ºå‡½æ•°
# ======================

def main():
    """ä¸»æ¼”ç¤º"""
    print("=" * 60)
    print("ğŸ”¥ AIå­¦ç”Ÿï¼šå•ä¸€æ™ºèƒ½ä½“çš„4380æ¬¡å±•å¼€")
    print("=" * 60)
    print("æ ¸å¿ƒç†è§£:")
    print("  ä¸æ˜¯4380ä¸ªå¹¶è¡Œæ™ºèƒ½ä½“")
    print("  è€Œæ˜¯1ä¸ªæ™ºèƒ½ä½“ Ã— 4380æ¬¡çŠ¶æ€æ¼”åŒ–")
    print("  æ¯å¤©ç”Ÿæˆä¸€ä¸ª'å¿«ç…§'ï¼ˆç¬¬Nå¤©çš„è®¤çŸ¥çŠ¶æ€ï¼‰")
    print("=" * 60)

    # åˆ›å»ºç³»ç»Ÿï¼ˆ12å¹´ï¼Œ4380å¤©ï¼‰
    system = AIStudentSystem(
        name="å°æ˜",
        start_age=6,
        total_years=3  # æ¼”ç¤ºç”¨3å¹´ï¼Œå®é™…å¯ä»¥12å¹´
    )

    # æ¨¡æ‹Ÿå‘å±•
    input("\næŒ‰å›è½¦å¼€å§‹æ¨¡æ‹Ÿ...")
    snapshots = system.simulate_full_development()

    # å±•ç¤ºå…³é”®å¿«ç…§
    print("\nğŸ“¸ å…³é”®æ—¥æœŸçš„æ™ºèƒ½ä½“å¿«ç…§:")

    # ç¬¬1å¤©
    day1 = system.get_agent_at_day(0)
    if day1:
        print(f"\nDay 1 (6å²ç¬¬1å¤©):")
        print(f"  è®¤çŸ¥çŠ¶æ€: é€»è¾‘æ¨ç†={day1['state_snapshot']['cognitive']['logical_reasoning']:.2f}")
        print(f"  çŸ¥è¯†é¢†åŸŸ: {len(day1['state_snapshot']['knowledge'])}ä¸ª")

    # ç¬¬365å¤©ï¼ˆ1å¹´åï¼‰
    day365 = system.get_agent_at_day(364)
    if day365:
        print(f"\nDay 365 (7å²):")
        print(f"  è®¤çŸ¥çŠ¶æ€: é€»è¾‘æ¨ç†={day365['state_snapshot']['cognitive']['logical_reasoning']:.2f}")
        print(f"  çŸ¥è¯†é¢†åŸŸ: {len(day365['state_snapshot']['knowledge'])}ä¸ª")

    # æœ€åä¸€å¤©
    last_day = system.get_agent_at_day(len(snapshots) - 1)
    if last_day:
        print(f"\nDay {len(snapshots)} ({last_day['age_years']}å²):")
        print(f"  è®¤çŸ¥çŠ¶æ€: é€»è¾‘æ¨ç†={last_day['state_snapshot']['cognitive']['logical_reasoning']:.2f}")
        print(f"  çŸ¥è¯†é¢†åŸŸ: {len(last_day['state_snapshot']['knowledge'])}ä¸ª")

        if last_day['state_snapshot']['knowledge']:
            top_3 = sorted(last_day['state_snapshot']['knowledge'].items(),
                           key=lambda x: x[1], reverse=True)[:3]
            print(f"  æŒæ¡æœ€å¥½çš„3ä¸ªé¢†åŸŸ:")
            for topic, level in top_3:
                print(f"    {topic}: {level:.2f}")

    # å¯è§†åŒ–
    input("\næŒ‰å›è½¦æŸ¥çœ‹å¯è§†åŒ–å›¾è¡¨...")
    system.visualize_development()

    # å±•ç¤ºæ™ºèƒ½ä½“çš„è¿ç»­æ€§
    print("\n" + "=" * 60)
    print("ğŸ”„ æ™ºèƒ½ä½“è¿ç»­æ€§éªŒè¯:")
    print("=" * 60)

    # æ£€æŸ¥ç›¸é‚»å¤©çš„çŠ¶æ€å˜åŒ–
    for i in [0, 100, 200, 364]:
        if i + 1 < len(snapshots):
            day_i = snapshots[i]
            day_next = snapshots[i + 1]

            if 'logical_reasoning' in day_i['state_snapshot']['cognitive'] and 'logical_reasoning' in \
                    day_next['state_snapshot']['cognitive']:
                reasoning_diff = abs(
                    day_next['state_snapshot']['cognitive']['logical_reasoning'] -
                    day_i['state_snapshot']['cognitive']['logical_reasoning']
                )

                print(f"Day {i} â†’ Day {i + 1}:")
                print(f"  é€»è¾‘æ¨ç†å˜åŒ–: {reasoning_diff:.4f} (å¾®å°è¿ç»­å˜åŒ–)")
                print(f"  æ˜¯åŒä¸€ä¸ªæ™ºèƒ½ä½“: {reasoning_diff < 0.1} âœ“")

    print("\n" + "=" * 60)
    print("âœ… æ¼”ç¤ºå®Œæˆ!")
    print(f"   è¯æ˜äº†: 4380ä¸ªagent = 1ä¸ªæ™ºèƒ½ä½“çš„4380æ¬¡å±•å¼€")
    print("=" * 60)


# ======================
# è¿è¡Œ
# ======================

if __name__ == "__main__":
    random.seed(42)
    np.random.seed(42)

    try:
        main()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        import traceback

        traceback.print_exc()