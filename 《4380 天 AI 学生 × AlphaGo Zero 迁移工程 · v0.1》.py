import math
import random
import copy

# ======================
# 1. ç©ºç™½å­¦ç”Ÿä½“ï¼ˆWorld Stateï¼‰
# ======================

def create_blank_student():
    return {
        "level": 0.5,
        "attention": 0.8,
        "fatigue": 0.2,
        "thinking_speed": 1.0,
        "allowed_formulas": [],
        "max_reasoning_chain": 1
    }

# ======================
# 2. ç‰›é¡¿è®¤çŸ¥ç”Ÿé•¿æ¨¡åž‹ï¼ˆ4380 å¤©ï¼‰
# ======================

def cognitive_stage(day):
    if day < 700:
        return "perception"
    elif day < 1500:
        return "rule"
    elif day < 2400:
        return "model"
    else:
        return "reasoning"

NEWTON_COGNITION = {
    "perception": {
        "formulas": ["v=s/t"],
        "chain": 1,
        "speed": 1.0
    },
    "rule": {
        "formulas": ["v=v0+at", "s=vt"],
        "chain": 2,
        "speed": 1.2
    },
    "model": {
        "formulas": ["s=v0t+1/2at^2"],
        "chain": 3,
        "speed": 1.5
    },
    "reasoning": {
        "formulas": ["free_combination"],
        "chain": 5,
        "speed": 2.0
    }
}

def newton_day_update(student, day):
    stage = cognitive_stage(day)
    cfg = NEWTON_COGNITION[stage]
    student["allowed_formulas"] = cfg["formulas"]
    student["max_reasoning_chain"] = cfg["chain"]
    student["thinking_speed"] = cfg["speed"]

# ======================
# 3. ä¸–ç•Œæ¨¡åž‹ï¼ˆæ•™å­¦è¡Œä¸ºï¼‰
# ======================

def apply_teaching_action(state, action):
    efficiency = state["attention"] * (1 - state["fatigue"])

    if action == "è®²è§£":
        gain = 0.15
        state["fatigue"] += 0.05
    elif action == "ä¾‹é¢˜":
        gain = 0.25
        state["fatigue"] += 0.08
    elif action == "åæ€":
        gain = 0.35
        state["fatigue"] -= 0.1
    elif action == "äº’åŠ¨å­¦ä¹ ":
        gain = 0.45
        state["fatigue"] += 0.05
    elif action == "ä¼‘æ¯":
        state["fatigue"] -= 0.2
        state["attention"] += 0.1
        return
    else:
        gain = 0.1

    state["fatigue"] = min(max(state["fatigue"], 0), 1)
    state["attention"] = min(max(state["attention"], 0), 1)

    state["level"] += gain * efficiency * state["thinking_speed"]

# ======================
# 4. å¥–åŠ±å‡½æ•°ï¼ˆå¯¹é½ç‰›é¡¿ï¼‰
# ======================

def alignment_reward(student):
    # å¥–åŠ± = èƒ½åŠ› Ã— ç¨³å®šæ€§ Ã— è¿›åº¦
    return (
        student["level"]
        * student["thinking_speed"]
        * (1 - abs(student["fatigue"] - 0.3))
    )

# ======================
# 5. æ•™è‚²ç‰ˆ MCTS
# ======================

ACTIONS = ["è®²è§£", "ä¾‹é¢˜", "åæ€", "äº’åŠ¨å­¦ä¹ ", "ä¼‘æ¯"]

class Node:
    def __init__(self, state, parent=None, action=None):
        self.state = state
        self.parent = parent
        self.action = action
        self.children = []
        self.visits = 0
        self.value = 0.0

    def ucb(self, c=1.4):
        if self.visits == 0:
            return float("inf")
        return self.value / self.visits + c * math.sqrt(
            math.log(self.parent.visits + 1) / self.visits
        )

def select(node):
    while node.children:
        node = max(node.children, key=lambda n: n.ucb())
    return node

def expand(node):
    for action in ACTIONS:
        s = copy.deepcopy(node.state)
        apply_teaching_action(s, action)
        node.children.append(Node(s, node, action))

def rollout(state, depth=5):
    s = copy.deepcopy(state)
    for _ in range(depth):
        apply_teaching_action(s, random.choice(ACTIONS))
    return alignment_reward(s)

def backprop(node, reward):
    while node:
        node.visits += 1
        node.value += reward
        node = node.parent

def mcts_decide(state, iterations=30):
    root = Node(copy.deepcopy(state))
    for _ in range(iterations):
        leaf = select(root)
        expand(leaf)
        child = random.choice(leaf.children)
        reward = rollout(child.state)
        backprop(child, reward)
    return max(root.children, key=lambda n: n.visits).action

# ======================
# 6. 4380 å¤©ä¸»æ¨¡æ‹Ÿ
# ======================

def simulate_4380_days():
    student = create_blank_student()
    history = []

    for day in range(4380):
        newton_day_update(student, day)
        action = mcts_decide(student)
        apply_teaching_action(student, action)

        history.append({
            "day": day,
            "stage": cognitive_stage(day),
            "level": round(student["level"], 2),
            "action": action
        })

        if day % 500 == 0:
            print(f"Day {day} | Stage {cognitive_stage(day)} | Level {student['level']:.2f}")

    return history

# ======================
# 7. è¿è¡Œå…¥å£
# ======================

if __name__ == "__main__":
    print("ðŸš€ å¯åŠ¨ AI å­¦ç”Ÿ 4380 å¤©è®¤çŸ¥ç”Ÿé•¿æ¨¡æ‹Ÿ")
    history = simulate_4380_days()
    print("âœ… æ¨¡æ‹Ÿå®Œæˆï¼Œæ€»å¤©æ•°ï¼š", len(history))
